# Importing required modules
from airflow import DAG
from airflow.decorators import task
from airflow.utils.dates import days_ago
from airflow.models import Variable
import requests
from datetime import datetime, timedelta
from airflow.providers.snowflake.hooks.snowflake import SnowflakeHook

default_args = {
    'owner': 'airflow',
    'start_date': days_ago(1),
}

dag = DAG(
    'stock_data_pipeline',
    default_args=default_args,
    description='A simple stock data pipeline',
    schedule_interval='@daily',
)

@task
def get_stock_data():
    api_key = Variable.get("Vantage_API_Key")
    symbol = "MSFT"
    url = f"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&apikey={api_key}"
    response = requests.get(url)
    response.raise_for_status()
    data = response.json()
    results = []
    # Calculate the date 90 days ago
    today = datetime.now().date()
    ninety_days_ago = today - timedelta(days=90)

    for date_str, daily_data in data["Time Series (Daily)"].items():
        date_obj = datetime.strptime(date_str, "%Y-%m-%d").date()
        if date_obj >= ninety_days_ago:
            stock_info = {
                "date": date_str,
                "open": daily_data["1. open"],
                "high": daily_data["2. high"],
                "low": daily_data["3. low"],
                "close": daily_data["4. close"],
                "volume": daily_data["5. volume"]
            }
            results.append(stock_info)
    return results

@task
def create_new_table():
    hook = SnowflakeHook(snowflake_conn_id='snowflake_conn')  
    conn = hook.get_conn()  # Get connection from hook
    create_table_query = """
    CREATE TABLE IF NOT EXISTS MY_NEW_DATABASE.RAW_DATA.NEW_TABLE (
        date DATE PRIMARY KEY,
        open FLOAT,
        high FLOAT,
        low FLOAT,
        close FLOAT,
        volume INTEGER,
        symbol STRING
    );
    """
    cur = conn.cursor()
    cur.execute(create_table_query)
    conn.commit()
    cur.close()

@task
def load_to_snowflake(stock_data):
    hook = SnowflakeHook(snowflake_conn_id='snowflake_conn')  # Use your Airflow connection ID
    conn = hook.get_conn()  # Get connection from hook
    insert_query = """
    INSERT INTO MY_NEW_DATABASE.RAW_DATA.NEW_TABLE (date, open, high, low, close, volume, symbol)
    VALUES (%s, %s, %s, %s, %s, %s, %s)
    """
    cur = conn.cursor()
    for record in stock_data:
        cur.execute(insert_query, (record['date'], record['open'], record['high'], record['low'], record['close'], record['volume'], 'MSFT'))
    conn.commit()
    cur.close()

@task
def check_table_stats():
    hook = SnowflakeHook(snowflake_conn_id='snowflake_conn')  # Use your Airflow connection ID
    conn = hook.get_conn()  # Get connection from hook
    cur = conn.cursor()
    result = cur.execute("SELECT COUNT(*) FROM MY_NEW_DATABASE.RAW_DATA.NEW_TABLE")
    count = result.fetchone()
    print(f"Number of records in the table: {count[0]}")
    cur.close()
    conn.close()

with dag:
    stock_data = get_stock_data()
    create_new_table()
    load_to_snowflake(stock_data)
    check_table_stats()
